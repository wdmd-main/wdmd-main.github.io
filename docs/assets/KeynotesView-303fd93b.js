import{Q as w,a8 as c,b0 as d,R as g,B as j,C as o,T as S,aa as E,al as x,X as h,Y as C,Z as p,ai as k,a1 as I,D as f,a2 as A,aj as N,_ as $,am as K,ae as L,a5 as T,a0 as t,a6 as b,az as u,aZ as D}from"./index-f157e92c.js";const F=w({tag:{type:String,default:"div"},span:{type:Number,default:24},offset:{type:Number,default:0},pull:{type:Number,default:0},push:{type:Number,default:0},xs:{type:c([Number,Object]),default:()=>d({})},sm:{type:c([Number,Object]),default:()=>d({})},md:{type:c([Number,Object]),default:()=>d({})},lg:{type:c([Number,Object]),default:()=>d({})},xl:{type:c([Number,Object]),default:()=>d({})}}),R=Symbol("rowContextKey"),O=g({name:"ElCol"}),U=g({...O,props:F,setup(m){const s=m,{gutter:a}=j(R,{gutter:o(()=>0)}),i=S("col"),l=o(()=>{const e={};return a.value&&(e.paddingLeft=e.paddingRight=`${a.value/2}px`),e}),y=o(()=>{const e=[];return["span","offset","pull","push"].forEach(n=>{const r=s[n];E(r)&&(n==="span"?e.push(i.b(`${s[n]}`)):r>0&&e.push(i.b(`${n}-${s[n]}`)))}),["xs","sm","md","lg","xl"].forEach(n=>{E(s[n])?e.push(i.b(`${n}-${s[n]}`)):x(s[n])&&Object.entries(s[n]).forEach(([r,v])=>{e.push(r!=="span"?i.b(`${n}-${r}-${v}`):i.b(`${n}-${v}`))})}),a.value&&e.push(i.is("guttered")),[i.b(),e]});return(e,_)=>(h(),C(N(e.tag),{class:I(f(y)),style:A(f(l))},{default:p(()=>[k(e.$slots,"default")]),_:3},8,["class","style"]))}});var H=$(U,[["__file","col.vue"]]);const M=K(H),B=["start","center","end","space-around","space-between","space-evenly"],P=["top","middle","bottom"],V=w({tag:{type:String,default:"div"},gutter:{type:Number,default:0},justify:{type:String,values:B,default:"start"},align:{type:String,values:P}}),Q=g({name:"ElRow"}),q=g({...Q,props:V,setup(m){const s=m,a=S("row"),i=o(()=>s.gutter);L(R,{gutter:i});const l=o(()=>{const e={};return s.gutter&&(e.marginRight=e.marginLeft=`-${s.gutter/2}px`),e}),y=o(()=>[a.b(),a.is(`justify-${s.justify}`,s.justify!=="start"),a.is(`align-${s.align}`,!!s.align)]);return(e,_)=>(h(),C(N(e.tag),{class:I(f(y)),style:A(f(l))},{default:p(()=>[k(e.$slots,"default")]),_:3},8,["class","style"]))}});var G=$(q,[["__file","row.vue"]]);const W=K(G);const Y=""+new URL("Sayed-3a100592.jpg",import.meta.url).href,J={class:"keynote-speakers"},Z={class:"keynotes"},X={class:"keynote"},z=["src"],ee=g({__name:"KeynotesView",setup(m){return(s,a)=>{const i=M,l=W;return h(),T("div",J,[a[2]||(a[2]=t("div",{class:"title1 font-merri title"},"WDMD 2025 Workshop Keynotes",-1)),a[3]||(a[3]=t("div",{class:"title-tip"},"DSN 2025",-1)),t("div",Z,[t("div",X,[b(l,{gutter:24},{default:p(()=>[b(i,{span:8},{default:p(()=>[t("img",{class:"img",src:f(Y)},null,8,z)]),_:1}),b(i,{span:16},{default:p(()=>a[0]||(a[0]=[t("div",{class:"name"},"Ahmed M. A. Sayed",-1),t("div",{class:"keynote-title"},[t("span",{class:"bold"},"Title: "),t("span",{class:"italic"},"Advancing Decentralized AI: Scalable, Adaptive, and Client-Centric Learning Systems")],-1),t("div",{class:"keynote-abstract"},[t("p",null,[t("span",{class:"bold"},"Abstract: "),t("span",{class:"italic"},"Decentralised AI systems, particularly those employing federated learning (FL), offer a promising approach to training machine learning models across distributed data sources while preserving privacy. However, they face significant challenges, including system heterogeneity, dynamic client availability, and resource constraints. Addressing these issues is crucial for the effective deployment of FL in real-world scenarios.")]),t("p",{class:"italic"},[u("In this talk, I will discuss our recent efforts to enhance the robustness and adaptability of FL systems. This includes the development of "),t("span",{class:"b"},"FLOAT"),u(", an automated tuning framework that dynamically optimises resource utilisation to meet training deadlines, mitigating stragglers and dropouts through various optimisation techniques. We also introduce "),t("span",{class:"b"},"REFL"),u(", a resource-efficient FL framework that decouples the collection of participant updates from model aggregation, intelligently selecting participants based on their likelihood of future availability to maximise resource utilisation. Additionally, "),t("span",{class:"b"},"QKT"),u(" is presented as a framework that enables tailored knowledge acquisition to fulfil specific client needs without direct data exchange, employing a data-free masking strategy to facilitate communication-efficient query-focused knowledge transfer while refining task-specific parameters to mitigate knowledge interference and forgetting. Our UKRI-EPSRC-funded project, "),t("span",{class:"b"},"KUber"),u(", addresses these challenges by developing a distributed knowledge delivery system to enhance FL scalability and efficiency. KUberâ€™s architecture facilitates seamless knowledge exchange among learning entities, optimising resource utilisation and model convergence")])],-1)])),_:1})]),_:1}),a[1]||(a[1]=t("div",{class:"keynote-bio"},[t("span",{class:"bold"},"Bio: "),t("span",{class:"italic"},"Ahmed M. A. Sayed is an Associate Professor at Queen Mary University of London, UK. He leads the Scalable Adaptive Yet Efficient Distributed (SAYED) Systems Research Group at QMUL. He received his Ph.D. in Computer Science and Engineering from Hong Kong University of Science and Technology, Hong Kong, in 2017. Formerly, he was a Research Scientist at KAUST, Saudi Arabia, and a Senior Researcher with Huawei's Future Networks Lab in Hong Kong. He is an investigator on several UK and international grants totalling nearly USD 1.5 million in funding. His research interests lie in the intersection of distributed systems, computer networks, and machine learning. His work appears in top-tier conferences and journals, including NeurIPS, AAAI, ICLR, MLSys, ACM EuroSys, IEEE INFOCOM, IEEE ICDCS, IEEE ICC/Globecom, IEEE/ACM ToN, IEEE IoTJ, IEEE TCC, IEEE TBD, IEEE TCSS, IEEE TIFS, Elsevier FGCS, IoT and Computer Networks.")],-1))])])])}}});const ae=D(ee,[["__scopeId","data-v-1f69c2df"]]);export{ae as default};
